@inproceedings{alva-manchego-etal-2021-deepquest,
    title = "deep{Q}uest-py: {L}arge and Distilled Models for Quality Estimation",
    author = "Alva-Manchego, Fernando  and
      Obamuyide, Abiola  and
      Gajbhiye, Amit  and
      Blain, Fr{\'e}d{\'e}ric  and
      Fomicheva, Marina  and
      Specia, Lucia",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-demo.42",
    pages = "382--389",
    abstract = "We introduce deepQuest-py, a framework for training and evaluation of large and light-weight models for Quality Estimation (QE). deepQuest-py provides access to (1) state-of-the-art models based on pre-trained Transformers for sentence-level and word-level QE; (2) light-weight and efficient sentence-level models implemented via knowledge distillation; and (3) a web interface for testing models and visualising their predictions. deepQuest-py is available at \url{https://github.com/sheffieldnlp/deepQuest-py} under a CC BY-NC-SA licence.",
}
